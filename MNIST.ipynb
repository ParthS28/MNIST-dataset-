{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
      "  0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      "  0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "  0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
      "  0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      "  0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
      "  0.99215686 0.35294118 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54509804\n",
      "  0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04313725\n",
      "  0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
      "  0.09803922 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      "  0.58823529 0.10588235 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
      "  0.99215686 0.73333333 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.97647059\n",
      "  0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      "  0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
      "  0.98039216 0.71372549 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09411765 0.44705882\n",
      "  0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
      "  0.30588235 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.21568627 0.6745098\n",
      "  0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "  0.52156863 0.04313725 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.53333333 0.99215686\n",
      "  0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc5a00ce7b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "plt.title(\"Digit {}\".format(y_train[0]))\n",
    "print(x_train[0])\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n",
      "(60000, 784, 1)\n",
      "(60000, 784, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "print(y_train.shape)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "print(y_test.shape)\n",
    "x_train = x_train.reshape((60000, 784, 1))\n",
    "print(x_train.shape)\n",
    "x_test = x_test.reshape((10000, 784, 1))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relU(a):\n",
    "    return np.maximum(0, a)\n",
    "\n",
    "def relU_prime(a):\n",
    "    return a > 0\n",
    "def relU__prime(a):\n",
    "    for i in range(len(a)):\n",
    "        a[i] = a[i] > 0\n",
    "    return a\n",
    "# Initialise weights\n",
    "w1 = np.random.rand(784, 16)\n",
    "w2 = np.random.rand(16, 16)\n",
    "w3 = np.random.rand(16, 10)\n",
    "# Initialise biases\n",
    "b1 = np.random.rand(1, 16)\n",
    "b2 = np.random.rand(1, 16)\n",
    "b3 = np.random.rand(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(s):\n",
    "    exps = np.exp(s - np.max(s, axis=1, keepdims=True))\n",
    "    return exps/np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "def forward_prop(x, w1, w2, w3, b1, b2, b3):\n",
    "    z1 = np.dot(x.T, w1) + b1\n",
    "    a1 = np.zeros(z1.shape)\n",
    "    for i in range(len(z1)):\n",
    "        a1[i] = relU(z1[i])\n",
    "    z2 = np.dot(a1, w2) + b2\n",
    "    a2 = np.zeros(z2.shape)\n",
    "    for i in range(len(z2)):\n",
    "        a2[i] = relU(z2[i])\n",
    "    z3 = np.dot(a2, w3) + b3\n",
    "    a3 = np.zeros(z3.shape)\n",
    "    a3 = softmax(z3)\n",
    "    #for i in range(len(z3)):\n",
    "        #a3[i] = softmax(z3[i])\n",
    "    return a1, a2, a3\n",
    "\n",
    "def back_prop(x, y, a1, a2, a3, w1, w2, w3, b1, b2, b3, lr):\n",
    "    a3_delta = a3 - y\n",
    "    z2_delta = np.dot(a3_delta, w3.T)\n",
    "    a2_delta = z2_delta * relU__prime(a2)\n",
    "    z1_delta = np.dot(a2_delta, w2.T)\n",
    "    a1_delta = z1_delta * relU__prime(a1)\n",
    "    w3 -= lr * np.dot(a2.T, a3_delta)\n",
    "    b3 -= lr * np.sum(a3_delta)\n",
    "    w2 -= lr * np.dot(a1.T, a2_delta)\n",
    "    b2 -= lr * np.sum(a2_delta)\n",
    "    w1 -= lr * np.dot(x, a1_delta)\n",
    "    b1 -= lr * np.sum(a1_delta)\n",
    "    return w1, w2, w3, b1, b2, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, w1, w2, w3, b1, b2, b3):\n",
    "    x = data\n",
    "    a1, a2, a3 = forward_prop(x, w1, w2, w3, b1, b2, b3)\n",
    "    return a3.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "\n",
    "for j in range(2000):\n",
    "    a1, a2, a3 = forward_prop(x_train[5], w1, w2, w3, b1, b2, b3)\n",
    "    w1, w2, w3, b1, b2, b3 = back_prop(x_train[5],y_train[5], a1, a2, a3, w1, w2, w3, b1, b2, b3, lr)\n",
    "    \n",
    "print(predict(x_train[5], w1, w2, w3, b1, b2, b3))\n",
    "print(y_train[5].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "for i in range(1000):\n",
    "    \n",
    "    for j in range(2000):\n",
    "        a1, a2, a3 = forward_prop(x_train[i], w1, w2, w3, b1, b2, b3)\n",
    "        w1, w2, w3, b1, b2, b3 = back_prop(x_train[i], y_train[i], a1, a2, a3, w1, w2, w3, b1, b2, b3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4783\n"
     ]
    }
   ],
   "source": [
    "#Score after training with only 1000/60000 \n",
    "score = 0\n",
    "for i in range(10000):\n",
    "    yt = y_test[i].argmax()\n",
    "    yp = predict(x_test[i], w1, w2, w3, b1, b2, b3)\n",
    "    if(yp == yt):\n",
    "        score = score + 1\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "for i in range(1000, 2000):\n",
    "    \n",
    "    for j in range(2000):\n",
    "        a1, a2, a3 = forward_prop(x_train[i], w1, w2, w3, b1, b2, b3)\n",
    "        w1, w2, w3, b1, b2, b3 = back_prop(x_train[i], y_train[i], a1, a2, a3, w1, w2, w3, b1, b2, b3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6877\n"
     ]
    }
   ],
   "source": [
    "#Score after training with 2000/60000\n",
    "score = 0\n",
    "for i in range(10000):\n",
    "    yt = y_test[i].argmax()\n",
    "    yp = predict(x_test[i], w1, w2, w3, b1, b2, b3)\n",
    "    if(yp == yt):\n",
    "        score = score + 1\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "for i in range(2000, 6000):\n",
    "    \n",
    "    for j in range(2000):\n",
    "        a1, a2, a3 = forward_prop(x_train[i], w1, w2, w3, b1, b2, b3)\n",
    "        w1, w2, w3, b1, b2, b3 = back_prop(x_train[i], y_train[i], a1, a2, a3, w1, w2, w3, b1, b2, b3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8291\n"
     ]
    }
   ],
   "source": [
    "#Score after training with 6000/60000 \n",
    "score = 0\n",
    "for i in range(10000):\n",
    "    yt = y_test[i].argmax()\n",
    "    yp = predict(x_test[i], w1, w2, w3, b1, b2, b3)\n",
    "    if(yp == yt):\n",
    "        score = score + 1\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "for i in range(6000, 10000):\n",
    "    \n",
    "    for j in range(2000):\n",
    "        a1, a2, a3 = forward_prop(x_train[i], w1, w2, w3, b1, b2, b3)\n",
    "        w1, w2, w3, b1, b2, b3 = back_prop(x_train[i], y_train[i], a1, a2, a3, w1, w2, w3, b1, b2, b3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8635\n"
     ]
    }
   ],
   "source": [
    "#Score after training with 10000/60000\n",
    "score = 0\n",
    "for i in range(10000):\n",
    "    yt = y_test[i].argmax()\n",
    "    yp = predict(x_test[i], w1, w2, w3, b1, b2, b3)\n",
    "    if(yp == yt):\n",
    "        score = score + 1\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "for i in range(10000, 30000):\n",
    "    \n",
    "    for j in range(2000):\n",
    "        a1, a2, a3 = forward_prop(x_train[i], w1, w2, w3, b1, b2, b3)\n",
    "        w1, w2, w3, b1, b2, b3 = back_prop(x_train[i], y_train[i], a1, a2, a3, w1, w2, w3, b1, b2, b3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8707\n"
     ]
    }
   ],
   "source": [
    "#Score after training with 30000/60000\n",
    "score = 0\n",
    "for i in range(10000):\n",
    "    yt = y_test[i].argmax()\n",
    "    yp = predict(x_test[i], w1, w2, w3, b1, b2, b3)\n",
    "    if(yp == yt):\n",
    "        score = score + 1\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "for i in range(30000, 40000):\n",
    "    \n",
    "    for j in range(2000):\n",
    "        a1, a2, a3 = forward_prop(x_train[i], w1, w2, w3, b1, b2, b3)\n",
    "        w1, w2, w3, b1, b2, b3 = back_prop(x_train[i], y_train[i], a1, a2, a3, w1, w2, w3, b1, b2, b3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8502\n"
     ]
    }
   ],
   "source": [
    "#Score after training 40000/60000\n",
    "score = 0\n",
    "for i in range(10000):\n",
    "    yt = y_test[i].argmax()\n",
    "    yp = predict(x_test[i], w1, w2, w3, b1, b2, b3)\n",
    "    if(yp == yt):\n",
    "        score = score + 1\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "for i in range(40000, 50000):\n",
    "    \n",
    "    for j in range(2000):\n",
    "        a1, a2, a3 = forward_prop(x_train[i], w1, w2, w3, b1, b2, b3)\n",
    "        w1, w2, w3, b1, b2, b3 = back_prop(x_train[i], y_train[i], a1, a2, a3, w1, w2, w3, b1, b2, b3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8642\n"
     ]
    }
   ],
   "source": [
    "#Score after training 50000/60000\n",
    "score = 0\n",
    "for i in range(10000):\n",
    "    yt = y_test[i].argmax()\n",
    "    yp = predict(x_test[i], w1, w2, w3, b1, b2, b3)\n",
    "    if(yp == yt):\n",
    "        score = score + 1\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "for i in range(50000, 60000):\n",
    "    \n",
    "    for j in range(2000):\n",
    "        a1, a2, a3 = forward_prop(x_train[i], w1, w2, w3, b1, b2, b3)\n",
    "        w1, w2, w3, b1, b2, b3 = back_prop(x_train[i], y_train[i], a1, a2, a3, w1, w2, w3, b1, b2, b3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8852\n"
     ]
    }
   ],
   "source": [
    "#Score after training 60000/60000\n",
    "score = 0\n",
    "for i in range(10000):\n",
    "    yt = y_test[i].argmax()\n",
    "    yp = predict(x_test[i], w1, w2, w3, b1, b2, b3)\n",
    "    if(yp == yt):\n",
    "        score = score + 1\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
